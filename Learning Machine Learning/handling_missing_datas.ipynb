{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb3f792-08fb-4cf2-8471-d4429b0834de",
   "metadata": {},
   "source": [
    "# Handling Missing DATAS\n",
    "The Titanic dataset contains several columns with missing data, making it a great example for learning how to handle missing values. This dataset includes information about passengers, such as age, gender, ticket fare, passenger class (pclass), and embarkation port (embarked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5979835-b41a-4117-bbc4-6e8451914677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "titanic_df = pd.read_csv(r\"C:\\Users\\Fuat\\Learning Machine Learning/Titanic-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e128f9-5436-47b9-8aea-19c9070ee02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8ada2-66bb-42ec-8b2a-4610418d150f",
   "metadata": {},
   "source": [
    "### Detecting Lost Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fecaff1-ad2e-400d-b890-7fe7b4a4205b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da63a7-c2cf-4a53-86ec-5d82114126cd",
   "metadata": {},
   "source": [
    "From this output:\n",
    "\n",
    "The age column has 177 missing values.\n",
    "\n",
    "The embarked and embark_town columns have 2 missing values each.\n",
    "\n",
    "The deck column has 688 missing values (this column is almost entirely empty)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8d3b8-dfca-46bf-b5e9-4b4fda074aff",
   "metadata": {},
   "source": [
    "## Methods for Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b4270-25a2-4965-bf75-c7c67345bd21",
   "metadata": {},
   "source": [
    "### Dropping Missing Data\n",
    "If the missing data is minimal, we can drop the rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0aec53-e934-47a9-96f0-fb9d2a2beafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "titanic_df_dropped = titanic_df.dropna()\n",
    "\n",
    "# Check for missing values again\n",
    "print(titanic_df_dropped.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225e964-a81e-4a4e-938c-4ae1dc369dc3",
   "metadata": {},
   "source": [
    "This method is not suitable for columns with a large number of missing values (e.g., the Cabin column), as it results in significant data loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f795b-6aad-45ac-8e6b-c36f129fba4d",
   "metadata": {},
   "source": [
    "### Filling Missing Data with Mean or Median\n",
    "For numerical columns, we can fill missing values with the column's mean or median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f96812-c986-4aac-a885-829e0071080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'age' column with the median\n",
    "\n",
    "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
    "\n",
    "\n",
    "# Fill missing values in the 'fare' column with the mean\n",
    "titanic_df['Fare'] = titanic_df['Fare'].fillna(titanic_df['Fare'].mean())\n",
    "\n",
    "# Check for missing values again\n",
    "print(titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744bfde-f801-4ff4-8c30-7703032b8f25",
   "metadata": {},
   "source": [
    "###  Filling Categorical Data with Mode\n",
    "For categorical columns, we can fill missing values with the mode (most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02457046-7caf-461a-8baa-46a1fe1f24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'embarked' and 'embark_town' columns with the mode\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
    "\n",
    "# Check for missing values again\n",
    "print(titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c28b6e-b026-428e-9a1c-32cd6ae07b3f",
   "metadata": {},
   "source": [
    "### Dropping Columns with Too Many Missing Values\n",
    "If a column has too many missing values (e.g., the Cabin column), we can drop the entire column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75139cd-b3f6-4896-8297-3df0fbf40a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Cabin' column\n",
    "titanic_df = titanic_df.drop(columns=['Cabin'])\n",
    "\n",
    "# Check for missing values again\n",
    "print(titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe8d6a-03f2-452e-bcc9-a7636551277c",
   "metadata": {},
   "source": [
    "## Advanced Methods: Imputation Using Prediction\n",
    "We can predict missing values based on other columns using machine learning techniques, such as K-Nearest Neighbors (KNN) or Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276f478-93e5-4961-88ad-10603e8bc50b",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Imputation\n",
    "KNN imputation works by finding the k most similar rows (neighbors) to the row with the missing value and using the average (or mode) of those neighbors to fill the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f9c298-e54c-4965-99ba-40885d38c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "********\n",
      "Age      0\n",
      "Fare     0\n",
      "SibSp    0\n",
      "Parch    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(r\"C:\\Users\\Fuat\\Learning Machine Learning/Titanic-Dataset.csv\")\n",
    "print(titanic_df.isnull().sum())\n",
    "print(\"********\")\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Select numerical columns for KNN imputation\n",
    "numerical_columns = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "\n",
    "# Initialize the KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)  # Use 5 nearest neighbors\n",
    "\n",
    "# Apply KNN imputation\n",
    "titanic_df[numerical_columns] = imputer.fit_transform(titanic_df[numerical_columns])\n",
    "\n",
    "# Check for missing values\n",
    "print(titanic_df[numerical_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16116b-646b-4193-a8b4-ccca3c72f14b",
   "metadata": {},
   "source": [
    "###  Random Forest Imputation\n",
    "Random Forest is a powerful machine learning algorithm that can be used to predict missing values by treating the column with missing values as the target variable and the other columns as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "558c7b4f-48cd-40b2-9c35-4214d4ea1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "********\n",
      "No missing values in Fare. Skipping imputation.\n",
      "Missing values after imputation:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "titanic_df = pd.read_csv(r\"C:\\Users\\Fuat\\Learning Machine Learning/Titanic-Dataset.csv\")\n",
    "\n",
    "print(\"Missing values before imputation:\")\n",
    "print(titanic_df.isnull().sum())\n",
    "print(\"********\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Sex', 'Embarked', 'Pclass']\n",
    "for col in categorical_columns:\n",
    "    titanic_df[col] = label_encoder.fit_transform(titanic_df[col].astype(str))\n",
    "\n",
    "# Drop irrelevant columns\n",
    "titanic_df = titanic_df.drop(columns=['Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "\n",
    "\n",
    "# Function for Random Forest Imputation\n",
    "def random_forest_impute(df, target_column):\n",
    "    # Check if the column has missing values\n",
    "    if df[target_column].isnull().sum() == 0:\n",
    "        print(f\"No missing values in {target_column}. Skipping imputation.\")\n",
    "        return df\n",
    "\n",
    "    # Separate rows with and without missing values\n",
    "    df_missing = df[df[target_column].isnull()]\n",
    "    df_not_missing = df[~df[target_column].isnull()]\n",
    "\n",
    "    # Prepare features (X) and target (y)\n",
    "    X = df_not_missing.drop(columns=[target_column])\n",
    "    y = df_not_missing[target_column]\n",
    "\n",
    "    # Ensure only numeric data is used\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "    X_missing = df_missing.drop(columns=[target_column]).select_dtypes(include=['number'])\n",
    "\n",
    "    # Check if data is sufficient for training\n",
    "    if X.empty or y.empty or X_missing.empty:\n",
    "        print(f\"Insufficient data for training the model for {target_column}.\")\n",
    "        return df\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict missing values\n",
    "    predicted_values = model.predict(X_missing)\n",
    "    df.loc[df[target_column].isnull(), target_column] = predicted_values\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply Random Forest Imputation\n",
    "if 'Age' in titanic_df.columns:\n",
    "    titanic_df = random_forest_impute(titanic_df, 'Age')\n",
    "\n",
    "if 'Fare' in titanic_df.columns:\n",
    "    titanic_df = random_forest_impute(titanic_df, 'Fare')\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"Missing values after imputation:\")\n",
    "print(titanic_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d15b9-54b1-48dd-9b61-d062370e2754",
   "metadata": {},
   "source": [
    "### Handling Categorical Data with Random Forest\n",
    "For categorical columns, you can use a RandomForestClassifier instead of a regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7aeebabe-bd28-468f-9ce4-e4f5d2573931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "********\n",
      "Missing Value in Embarked Column:  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "titanic_df = pd.read_csv(r\"C:\\Users\\Fuat\\Learning Machine Learning/Titanic-Dataset.csv\")\n",
    "\n",
    "print(\"Missing values before imputation:\")\n",
    "print(titanic_df.isnull().sum())\n",
    "print(\"********\") \n",
    "\n",
    "\n",
    "def random_forest_impute_categorical(df, target_column):\n",
    "    # Check if the target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise KeyError(f\"Column '{target_column}' not found in DataFrame.\")\n",
    "    \n",
    "    # Check for missing values in the target column\n",
    "    if df[target_column].isnull().sum() == 0:\n",
    "        print(f\"No missing values in '{target_column}' to impute.\")\n",
    "        return df\n",
    "    \n",
    "    # Extract the target column and drop it from the features\n",
    "    y = df[target_column]\n",
    "    df_features = df.drop(columns=[target_column])\n",
    "    \n",
    "    # Drop non-numeric columns (customize this list as needed)\n",
    "    df_features = df_features.drop(columns=['Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df_encoded = pd.get_dummies(df_features, drop_first=True)\n",
    "    \n",
    "    # Combine encoded features with the target column\n",
    "    df_combined = pd.concat([df_encoded, y], axis=1)\n",
    "    \n",
    "    # Split into missing and non-missing data\n",
    "    df_missing = df_combined[df_combined[target_column].isnull()]\n",
    "    df_not_missing = df_combined[~df_combined[target_column].isnull()]\n",
    "    \n",
    "    # Check if there are samples with missing values to impute\n",
    "    if df_missing.empty:\n",
    "        print(f\"No rows with missing '{target_column}' to impute.\")\n",
    "        return df\n",
    "    \n",
    "    # Features and target\n",
    "    X = df_not_missing.drop(columns=[target_column])\n",
    "    y = df_not_missing[target_column]\n",
    "    \n",
    "    # Train a Random Forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict missing values\n",
    "    X_missing = df_missing.drop(columns=[target_column])\n",
    "    predicted_values = model.predict(X_missing)\n",
    "    \n",
    "    # Fill the missing values in the ORIGINAL DataFrame (not the encoded one)\n",
    "    df.loc[df[target_column].isnull(), target_column] = predicted_values\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to 'Embarked' (ensure case matches your DataFrame)\n",
    "titanic_df = random_forest_impute_categorical(titanic_df, 'Embarked')  # Use 'embarked' if column is lowercase\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Value in Embarked Column: \",  titanic_df['Embarked'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f6472-0876-4bb3-9cb5-063526b6ec1b",
   "metadata": {},
   "source": [
    "### Combining KNN and Random Forest\n",
    "You can combine both methods to handle different types of missing data:\n",
    "\n",
    "Use KNN for numerical columns.\n",
    "\n",
    "Use Random Forest for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8a31c76-ff80-4ec4-bb0c-fba4c273869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "********\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "titanic_df = pd.read_csv(r\"C:\\Users\\Fuat\\Learning Machine Learning/Titanic-Dataset.csv\")\n",
    "\n",
    "print(\"Missing values before imputation:\")\n",
    "print(titanic_df.isnull().sum())\n",
    "print(\"********\")\n",
    "\n",
    "# Apply KNN imputation for numerical columns\n",
    "numerical_columns = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "titanic_df[numerical_columns] = imputer.fit_transform(titanic_df[numerical_columns])\n",
    "\n",
    "# Apply Random Forest imputation for categorical columns\n",
    "categorical_columns = ['Embarked']\n",
    "for column in categorical_columns:\n",
    "    titanic_df = random_forest_impute_categorical(titanic_df, column)\n",
    "\n",
    "# Check for missing values\n",
    "print(titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95167bc-6cbd-4f9b-8bc7-a5ec69f553e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
